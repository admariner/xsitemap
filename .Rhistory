#' @export
#'
getXMLSitemapFromRobotsTxt <- function(urltocheck, user_agent) {
if (missing(user_agent)) {
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
}
if ("/robots.txt" != substr(urltocheck, nchar(urltocheck) - 10, nchar(urltocheck))) {
urltocheck <- paste0(urltocheck, "robots.txt")
}
request <- httr::GET(urltocheck, user_agent(user_agent))
if (request$status_code == 200) {
robotstext <- httr::content(request)
if (stringr::str_detect(robotstext, "\nSitemap:")) {
message("XML sitemap url detect inside robots.txt")
#library(stringr)
xml_url <- stringr::str_match(robotstext, "Sitemap: (.*)(\\n|$)")[, 2]
message(xml_url)
return(paste0("", xml_url))
} else{
message("No XML sitemap url inside robots.txt")
return("")
}
} else{
message("no robots.txt")
return("")
}
wordpress_paths <-
c("catalog_entries-sitemap.xml",
"category-sitemap.xml",
"dt_catalog-sitemap.xml",
"dt_portfolios-sitemap.xml",
"ngg_tag-sitemap.xml",
"page-sitemap.xml",
"portfolio_entries-sitemap.xml",
"post-sitemap.xml",
"post_tag-sitemap.xml",
"product-sitemap.xml",
"product_cat-sitemap.xml",
"product_shipping_class-sitemap.xml",
"product_tag-sitemap.xml"
)
#'
#' Check if xml sitemap urls send a 200 http code
#'
#' @param sitemap dataframe
#' @param user_agent User agent string to http request
#'
#' @return dataframe
#' @export
#'
#' @examples
getXMLSitemapHTTP <- function(sitemap, user_agent) {
message(paste("getXMLSitemapHTTP :", nrow(sitemap), " URL(s) to check"))
if (missing(user_agent)) {
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
}
sitemap["http"] <- NA
for (i in 1:nrow(sitemap)) {
#progress.bar = TRUE
cat(".")
request <- HEAD(sitemap[i,]$loc, user_agent(user_agent))
sitemap[i,]$http <- request$status_code
}
return(sitemap)
}
#'surement la description la plus courte du monde
#' ????
#'
#' ??
#' @param urltocheck hostname string of the website you want to guess xml sitemap url
#' @param user_agent user agent string to http request
#'
#' @return dataframe
#' @export
#'
guessXMLSitemap <- function(urltocheck, user_agent) {
message("Guessing for XML Sitemap URL...")
test_paths <-
c(
"sitemap_index.xml",
"sitemaps.xml",
"sitemap.xml",
"sitemap-index.xml",
"sitemap.xml.gz"
)
if (missing(user_agent)) {
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
}
for (paths in test_paths) {
cat(paths)
request <-
httr::GET(paste0(urltocheck, paths), user_agent(user_agent))
if (request$status_code == 200) {
message(" OK")
return (paste0(urltocheck, paths))
} else{
message(" KO")
}
wordpress_paths <-
c("catalog_entries-sitemap.xml",
"category-sitemap.xml",
"dt_catalog-sitemap.xml",
"dt_portfolios-sitemap.xml",
"ngg_tag-sitemap.xml",
"page-sitemap.xml",
"portfolio_entries-sitemap.xml",
"post-sitemap.xml",
"post_tag-sitemap.xml",
"product-sitemap.xml",
"product_cat-sitemap.xml",
"product_shipping_class-sitemap.xml",
"product_tag-sitemap.xml"
)
test <- checkWordpressXMLSitemap("https://www.gokam.fr/")
#' checkWordpressXMLSitemaps
#'
#' check classic wordpress urls http code and return it inside the original data frame
#' @param domain
#' @param user_agent
#'
#' @return data frame
#' @export
#'
#' @examples
checkWordpressXMLSitemaps <- function(domain, user_agent) {
wordpress_paths <-
c("catalog_entries-sitemap.xml",
"category-sitemap.xml",
"dt_catalog-sitemap.xml",
"dt_portfolios-sitemap.xml",
"ngg_tag-sitemap.xml",
"page-sitemap.xml",
"portfolio_entries-sitemap.xml",
"post-sitemap.xml",
"post_tag-sitemap.xml",
"product-sitemap.xml",
"product_cat-sitemap.xml",
"product_shipping_class-sitemap.xml",
"product_tag-sitemap.xml"
)
urls <- data.frame(
loc = paste0(domain,wordpress_paths),
stringsAsFactors = FALSE
)
getXMLSitemapHTTP(urls, user_agent)
}
test <- checkWordpressXMLSitemap("https://www.gokam.fr/")
#' checkWordpressXMLSitemaps
#'
#' check classic wordpress urls http code and return it inside the original data frame
#' @param domain
#' @param user_agent
#'
#' @return data frame
#' @export
#'
#' @examples
checkWordpressXMLSitemaps <- function(domain, user_agent) {
wordpress_paths <-
c("catalog_entries-sitemap.xml",
"category-sitemap.xml",
"dt_catalog-sitemap.xml",
"dt_portfolios-sitemap.xml",
"ngg_tag-sitemap.xml",
"page-sitemap.xml",
"portfolio_entries-sitemap.xml",
"post-sitemap.xml",
"post_tag-sitemap.xml",
"product-sitemap.xml",
"product_cat-sitemap.xml",
"product_shipping_class-sitemap.xml",
"product_tag-sitemap.xml"
)
urls <- data.frame(
loc = paste0(domain,wordpress_paths),
stringsAsFactors = FALSE
)
getXMLSitemapHTTP(urls, user_agent)
}
test <- getXMLSitemapHTTP("https://www.gokam.fr/")
#' checkWordpressXMLSitemaps
#'
#' check classic wordpress urls http code and return it inside the original data frame
#' @param domain
#' @param user_agent
#'
#' @return data frame
#' @export
#'
#' @examples
checkWordpressXMLSitemaps <- function(domain, user_agent) {
wordpress_paths <-
c("catalog_entries-sitemap.xml",
"category-sitemap.xml",
"dt_catalog-sitemap.xml",
"dt_portfolios-sitemap.xml",
"ngg_tag-sitemap.xml",
"page-sitemap.xml",
"portfolio_entries-sitemap.xml",
"post-sitemap.xml",
"post_tag-sitemap.xml",
"product-sitemap.xml",
"product_cat-sitemap.xml",
"product_shipping_class-sitemap.xml",
"product_tag-sitemap.xml"
)
urls <- data.frame(
loc = paste0(domain,wordpress_paths),
stringsAsFactors = FALSE
)
getXMLSitemapHTTP(urls, user_agent)
}
test <- getXMLSitemapHTTP("https://www.gokam.fr/")
#'
#' Check if xml sitemap urls send a 200 http code
#'
#' @param sitemap dataframe
#' @param user_agent User agent string to http request
#'
#' @return dataframe
#' @export
#'
#' @examples
getXMLSitemapHTTP <- function(sitemap) {
message(paste("getXMLSitemapHTTP :", nrow(sitemap), " URL(s) to check"))
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
sitemap["http"] <- NA
for (i in 1:nrow(sitemap)) {
#progress.bar = TRUE
cat(".")
request <- HEAD(sitemap[i,]$loc, user_agent(user_agent))
sitemap[i,]$http <- request$status_code
}
return(sitemap)
}
#' checkWordpressXMLSitemaps
#'
#' check classic wordpress urls http code and return it inside the original data frame
#' @param domain
#' @param user_agent
#'
#' @return data frame
#' @export
#'
#' @examples
checkWordpressXMLSitemaps <- function(domain) {
wordpress_paths <-
c("catalog_entries-sitemap.xml",
"category-sitemap.xml",
"dt_catalog-sitemap.xml",
"dt_portfolios-sitemap.xml",
"ngg_tag-sitemap.xml",
"page-sitemap.xml",
"portfolio_entries-sitemap.xml",
"post-sitemap.xml",
"post_tag-sitemap.xml",
"product-sitemap.xml",
"product_cat-sitemap.xml",
"product_shipping_class-sitemap.xml",
"product_tag-sitemap.xml"
)
urls <- data.frame(
loc = paste0(domain,wordpress_paths),
stringsAsFactors = FALSE
)
getXMLSitemapHTTP(urls, user_agent)
}
#'surement la description la plus courte du monde
#' ????
#'
#' ??
#' @param urltocheck hostname string of the website you want to guess xml sitemap url
#' @param user_agent user agent string to http request
#'
#' @return dataframe
#' @export
#'
guessXMLSitemap <- function(urltocheck) {
message("Guessing for XML Sitemap URL...")
test_paths <-
c(
"sitemap_index.xml",
"sitemaps.xml",
"sitemap.xml",
"sitemap-index.xml",
"sitemap.xml.gz"
)
if (missing(user_agent)) {
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
}
for (paths in test_paths) {
cat(paths)
request <-
httr::GET(paste0(urltocheck, paths), user_agent(user_agent))
if (request$status_code == 200) {
message(" OK")
return (paste0(urltocheck, paths))
} else{
message(" KO")
}
for (paths in test_paths) {
cat(paths)
request <-
httr::GET(paste0(urltocheck, paths), user_agent(user_agent))
if (request$status_code == 200) {
message(" OK")
return (paste0(urltocheck, paths))
} else{
message(" KO")
}
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
#' getXMLSitemapFromRobotsTxt
#' ceci est un description tres partiel
#' @param urltocheck hostname string of the website you want to find xml sitemap from robots
#' @param user_agent user agent string to http request
#'
#' @return string
#' @export
#'
getXMLSitemapFromRobotsTxt <- function(urltocheck) {
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
if ("/robots.txt" != substr(urltocheck, nchar(urltocheck) - 10, nchar(urltocheck))) {
urltocheck <- paste0(urltocheck, "robots.txt")
}
request <- httr::GET(urltocheck, user_agent(user_agent))
if (request$status_code == 200) {
robotstext <- httr::content(request)
if (stringr::str_detect(robotstext, "\nSitemap:")) {
message("XML sitemap url detect inside robots.txt")
#library(stringr)
xml_url <- stringr::str_match(robotstext, "Sitemap: (.*)(\\n|$)")[, 2]
message(xml_url)
return(paste0("", xml_url))
} else{
message("No XML sitemap url inside robots.txt")
return("")
}
} else{
message("no robots.txt")
return("")
}
test <- getXMLSitemapHTTP("https://www.gokam.fr/")
#'
#' Check if xml sitemap urls send a 200 http code
#'
#' @param sitemap dataframe
#' @param user_agent User agent string to http request
#'
#' @return dataframe
#' @export
#'
#' @examples
getXMLSitemapHTTP <- function(sitemap) {
message(paste("getXMLSitemapHTTP :", nrow(sitemap), " URL(s) to check"))
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
sitemap["http"] <- NA
for (i in 1:nrow(sitemap)) {
#progress.bar = TRUE
cat(".")
request <- HEAD(sitemap[i,]$loc, user_agent(user_agent))
sitemap[i,]$http <- request$status_code
}
return(sitemap)
}
test <- getXMLSitemapHTTP("https://www.gokam.fr/")
test <- getXMLSitemap("https://www.gokam.fr/")
#'surement la description la plus courte du monde
#' ????
#'
#' ??
#' @param urltocheck hostname string of the website you want to guess xml sitemap url
#' @param user_agent user agent string to http request
#'
#' @return dataframe
#' @export
#'
guessXMLSitemap <- function(urltocheck) {
message("Guessing for XML Sitemap URL...")
test_paths <-
c(
"sitemap_index.xml",
"sitemaps.xml",
"sitemap.xml",
"sitemap-index.xml",
"sitemap.xml.gz"
)
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
for (paths in test_paths) {
cat(paths)
request <-
httr::GET(paste0(urltocheck, paths), user_agent(user_agent))
if (request$status_code == 200) {
message(" OK")
return (paste0(urltocheck, paths))
} else{
message(" KO")
}
test <- getXMLSitemap("https://www.gokam.fr/")
test <- getXMLSitemapHTTP("https://www.gokam.fr/")
?url_parse
library(XML)
?url_parse
??url_parse
test <- getXMLSitemapHTTP("https://www.gokam.fr/")
test <- getXMLSitemap("https://www.gokam.fr/")
#' getXMLSitemap
#'
#' @param urltocheck direct xml sitemap url or hostname string of the website you want to find xml sitemap from
#'
#' @return dataframe
#' @export
#'
getXMLSitemap <- function(urltocheck) {
user_agent <-
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
URL <- url_parse(urltocheck)
if (is.na(URL$path) && !is.na(URL$domain)) {
message("Searching for XML Sitemap URL...")
# Reaching for robots.txt to find XML Sitemap
xmlsitemap_from_robots <- getXMLSitemapFromRobotsTxt(urltocheck)
if (xmlsitemap_from_robots != "") {
getXMLSitemap(xmlsitemap_from_robots)
} else {
xmlsitemap_from_guessing <- guessXMLSitemap(urltocheck)
if (!is.null(xmlsitemap_from_guessing)) {
getXMLSitemap(xmlsitemap_from_guessing)
} else{
warning("Can't find xml sitemap url :(")
return(FALSE)
}
} else if (!is.na(URL$path)) {
message(paste("Reaching for XML sitemap...", urltocheck))
request <- GET(urltocheck, user_agent(user_agent))
if(request$status_code != 200 && request$status_code != 301){
warning(paste("xml sitemap is not accessible (HTTP:",request$status_code))
return(NULL)
}
xml_doc <- xmlParse(request, encoding = "UTF-8")
xml_data <- xmlToList(xml_doc)
nb_children <- length(xml_data)
#message(paste(" ", nb_children, " URL(s) found"))
test_url <- lapply(xml_data, `[[`, 1)[1]
#message(paste("test_url >", test_url))
url_split <- strsplit(toString(test_url), "\\.")
if ("xml" == mapply(`[`, url_split, lengths(url_split))) {
if (nb_children < 50001) {
message(paste(
"sitemap index detected - ",
nb_children,
" sitemap url(s) found"
))
} else{
warning(paste("too many URLs - ",
nb_children,
" web page url(s) found"))
return(NULL)
}
urls <- data.frame(
loc = character(),
lastmod = as.Date(character(), format = "%Y-%m-%d"),
stringsAsFactors = FALSE
)
for (i in 1:nb_children) {
individual_sitemap <-  xml_data[i]$sitemap$loc
message(paste0("\n", i, " >>> ", individual_sitemap))
new_urls <- getXMLSitemap(individual_sitemap)
new_urls$origin <- urltools::url_parse(individual_sitemap)$path
urls <- rbind(urls, new_urls)
}
return(urls)
} else{
# if (nb_children < 50000) {
message(paste(
"regular sitemap detected - ",
nb_children,
" web page url(s) found"
))
#} else{
#  warning(paste("too many URLs - ",
#                nb_children,
#                " web page url(s) found"))
#  return(NULL)
#urls <- vector(mode = "character", length = 0)
urls <- data.frame(
loc = character(),
lastmod = as.Date(character(), format = "%Y-%m-%d"),
stringsAsFactors = FALSE
)
for (i in 1:(nb_children - 1)) {
cat(".")
urls[i, ]$loc <- xml_data[i]$url$loc
if (!is.null(xml_data[i]$url$lastmod)) {
urls[i, ]$lastmod <- xml_data[i]$url$lastmod
}
return(urls)
}
} else{
stop("Mal formatted url")
#return NA
}
test <- getXMLSitemap("https://www.gokam.fr/")
library(urltools)
test <- getXMLSitemap("https://www.gokam.fr/")
